{"uuid": "893bbc33-4208-4748-9e2d-421ee2abd177", "provider": "UNKNOWN", "num_cpu": 128, "cpu_type": "Intel(R) Xeon(R) Platinum 8462Y+", "cpu_family_model_stepping": "6,143,8", "total_memory": 2162800443392, "architecture": "x86_64", "platform": "Linux-6.5.13-65-650-4141-22041-coreweave-amd64-85c45edc-x86_64-with-glibc2.39", "cuda_runtime": "12.4", "gpu_count": 8, "gpu_type": "NVIDIA H100 80GB HBM3", "gpu_memory_per_device": 84942979072, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.7.3", "context": "LLM_CLASS", "log_time": 1740819894857643008, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 8, "block_size": 16, "gpu_memory_utilization": 0.8, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": false, "enforce_eager": false, "disable_custom_all_reduce": false}
{"uuid": "186ce8c8-923d-4b5f-92fd-f2c8fef17fb1", "provider": "UNKNOWN", "num_cpu": 128, "cpu_type": "Intel(R) Xeon(R) Platinum 8462Y+", "cpu_family_model_stepping": "6,143,8", "total_memory": 2162800443392, "architecture": "x86_64", "platform": "Linux-6.5.13-65-650-4141-22041-coreweave-amd64-85c45edc-x86_64-with-glibc2.39", "cuda_runtime": "12.4", "gpu_count": 8, "gpu_type": "NVIDIA H100 80GB HBM3", "gpu_memory_per_device": 84942979072, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.7.3", "context": "LLM_CLASS", "log_time": 1740819978427346944, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 8, "block_size": 16, "gpu_memory_utilization": 0.8, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": false, "enforce_eager": false, "disable_custom_all_reduce": false}
{"uuid": "beb32351-be6d-4c9b-a82a-600bc28f2126", "provider": "UNKNOWN", "num_cpu": 128, "cpu_type": "Intel(R) Xeon(R) Platinum 8462Y+", "cpu_family_model_stepping": "6,143,8", "total_memory": 2162800443392, "architecture": "x86_64", "platform": "Linux-6.5.13-65-650-4141-22041-coreweave-amd64-85c45edc-x86_64-with-glibc2.39", "cuda_runtime": "12.4", "gpu_count": 8, "gpu_type": "NVIDIA H100 80GB HBM3", "gpu_memory_per_device": 84942979072, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.7.3", "context": "LLM_CLASS", "log_time": 1740820115243330048, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 8, "block_size": 16, "gpu_memory_utilization": 0.8, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": false, "enforce_eager": true, "disable_custom_all_reduce": false}
{"uuid": "96f689c7-a2e1-4fad-8822-b87ee0d0bc29", "provider": "UNKNOWN", "num_cpu": 128, "cpu_type": "Intel(R) Xeon(R) Platinum 8462Y+", "cpu_family_model_stepping": "6,143,8", "total_memory": 2162800443392, "architecture": "x86_64", "platform": "Linux-6.5.13-65-650-4141-22041-coreweave-amd64-85c45edc-x86_64-with-glibc2.39", "cuda_runtime": "12.4", "gpu_count": 8, "gpu_type": "NVIDIA H100 80GB HBM3", "gpu_memory_per_device": 84942979072, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.7.3", "context": "LLM_CLASS", "log_time": 1740820185613224960, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 8, "block_size": 16, "gpu_memory_utilization": 0.8, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": false, "enforce_eager": true, "disable_custom_all_reduce": false}
{"uuid": "be165bf8-21bc-4d54-a0d6-f5b7a7e33293", "provider": "UNKNOWN", "num_cpu": 128, "cpu_type": "Intel(R) Xeon(R) Platinum 8462Y+", "cpu_family_model_stepping": "6,143,8", "total_memory": 2162800443392, "architecture": "x86_64", "platform": "Linux-6.5.13-65-650-4141-22041-coreweave-amd64-85c45edc-x86_64-with-glibc2.39", "cuda_runtime": "12.4", "gpu_count": 8, "gpu_type": "NVIDIA H100 80GB HBM3", "gpu_memory_per_device": 84942979072, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.7.3", "context": "LLM_CLASS", "log_time": 1740820341552342784, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 8, "block_size": 16, "gpu_memory_utilization": 0.8, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": false, "enforce_eager": true, "disable_custom_all_reduce": false}
{"uuid": "c2ea9417-2d87-4c61-97cd-3f6bf29e50f7", "provider": "UNKNOWN", "num_cpu": 128, "cpu_type": "Intel(R) Xeon(R) Platinum 8462Y+", "cpu_family_model_stepping": "6,143,8", "total_memory": 2162800443392, "architecture": "x86_64", "platform": "Linux-6.5.13-65-650-4141-22041-coreweave-amd64-85c45edc-x86_64-with-glibc2.39", "cuda_runtime": "12.4", "gpu_count": 8, "gpu_type": "NVIDIA H100 80GB HBM3", "gpu_memory_per_device": 84942979072, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.7.3", "context": "LLM_CLASS", "log_time": 1740820584103632896, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 8, "block_size": 16, "gpu_memory_utilization": 0.8, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": false, "enforce_eager": true, "disable_custom_all_reduce": false}
